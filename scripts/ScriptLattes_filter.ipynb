{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "\n",
        "folder = '/content/'\n",
        "extraction_number = '06'\n",
        "\n",
        "KEYWORDS = [\n",
        "    'divulgação científica', 'divulgacao cientifica', 'popularização da ciência',\n",
        "    'popularizacao da ciencia', 'ensino de ciência', 'educação científica',\n",
        "    'educacao cientifica', 'ciência para crianças', 'ciencia para criancas',\n",
        "    'curiosidades científicas', 'curiosidades cientificas', 'ciencion',\n",
        "    'revista ciência', 'revista galileu', 'superinteressante', 'ciência hoje',\n",
        "    'ciencia hoje', 'blog', 'contém química', 'dragões de garagem',\n",
        "    'guia dos entusiastas', 'ciência viva', 'scicast', 'ciência aberta',\n",
        "    'jornal da usp', 'comciência', 'museus de ciência', 'museu de ciência',\n",
        "    'jornalismo científico', 'alfabetização científica', 'texto de divulgação',\n",
        "    'postagem', 'podcast', 'rádio', 'entrevista', 'programa', 'mesa redonda',\n",
        "    'live', 'vídeo', 'youtube', 'canal', 'tv', 'documentário', 'série',\n",
        "    'reportagem', 'webinar', 'rede social', 'spotify', 'instagram',\n",
        "    'facebook'\n",
        "]\n",
        "\n",
        "def find_keyword(input_text):\n",
        "    if not isinstance(input_text, str):\n",
        "        return False\n",
        "    input_text = input_text.lower()\n",
        "    return any(p in input_text for p in KEYWORDS)\n",
        "\n",
        "csv_files = glob.glob(os.path.join(folder, '*.csv'))\n",
        "dfs_dc = []\n",
        "\n",
        "for path in csv_files:\n",
        "    if path.startswith(f'{folder}{extraction_number} - '):\n",
        "        print(f'path: {path}')\n",
        "        df = pd.read_csv(path, sep=None, engine='python', encoding='utf-8')\n",
        "        df['text_join'] = df.apply(lambda x: ' '.join(str(v) for v in x), axis=1)\n",
        "        df_dc = df[df['text_join'].apply(find_keyword)].drop(columns=['text_join'])\n",
        "\n",
        "        if not df_dc.empty:\n",
        "            df_dc['source_file'] = os.path.basename(path)\n",
        "            dfs_dc.append(df_dc)\n",
        "\n",
        "if dfs_dc:\n",
        "    df_dc_output = pd.concat(dfs_dc, ignore_index=True)\n",
        "    output_path = os.path.join(folder, f'output - {extraction_number}.csv')\n",
        "    df_dc_output.to_csv(output_path, index=False, sep=';', encoding='utf-8-sig')\n",
        "    print(f'output_path: {output_path}')\n",
        "    print(f'total rows: {len(df_dc_output)}')\n",
        "\n",
        "    if 'Autores' in df_dc_output.columns:\n",
        "        autores_explode = (\n",
        "            df_dc_output['Autores']\n",
        "            .dropna()\n",
        "            .astype(str)\n",
        "            .str.replace(r'\\s*;\\s*', ';', regex=True)\n",
        "            .str.split(';')\n",
        "            .explode()\n",
        "            .str.strip()\n",
        "        )\n",
        "\n",
        "        autores_explode = autores_explode[autores_explode != \"\"]\n",
        "        autores_explode = (\n",
        "            autores_explode\n",
        "            .str.lower()\n",
        "            .str.replace(r'\\(org\\.\\)', '', regex=True)\n",
        "            .str.replace(r'\\borgs?\\b', '', regex=True)\n",
        "            .str.replace(r'[\\.,]', '', regex=True)\n",
        "            .str.replace(r'\\s+', ' ', regex=True)\n",
        "            .str.strip()\n",
        "        )\n",
        "\n",
        "        autores_explode = autores_explode[autores_explode != \"\"]\n",
        "        autor_counts = autores_explode.value_counts().reset_index()\n",
        "        autor_counts.columns = ['Autor', 'Count']\n",
        "\n",
        "        autor_counts = autor_counts.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
        "\n",
        "        authors_path = os.path.join(folder, f'distinct_authors - {extraction_number}.csv')\n",
        "        autor_counts.to_csv(authors_path, index=False, sep=';', encoding='utf-8-sig')\n",
        "\n",
        "        print(f'authors_path: {authors_path}')\n",
        "        print(f'total unique authors: {len(autor_counts)}')"
      ],
      "metadata": {
        "id": "mLc_Hk7OFXvK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}